{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD Object Detection для BCCD Dataset\n",
    "\n",
    "Этот notebook реализует Single Shot MultiBox Detector (SSD300) для детекции клеток крови.\n",
    "\n",
    "## Содержание:\n",
    "1. Установка зависимостей и загрузка данных\n",
    "2. Визуализация данных\n",
    "3. Создание модели SSD300\n",
    "4. Обучение модели\n",
    "5. Оценка результатов\n",
    "6. Inference на тестовых изображениях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Установка зависимостей и загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка зависимостей\n",
    "!pip install torch torchvision numpy matplotlib Pillow tqdm opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Клонирование датасета BCCD\n",
    "!git clone https://github.com/Shenggan/BCCD_Dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Импорт модулей проекта\n",
    "import config\n",
    "from model import SSD300\n",
    "from dataset import BCCDDataset, create_dataloaders, TrainTransform, TestTransform\n",
    "from utils import create_prior_boxes, MultiBoxLoss, parse_voc_annotation\n",
    "from inference import detect, visualize_detection\n",
    "\n",
    "print(f'PyTorch версия: {torch.__version__}')\n",
    "print(f'Устройство: {config.DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Визуализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка одного примера из датасета\n",
    "sample_image_path = 'BCCD_Dataset/BCCD/JPEGImages/BloodImage_00000.jpg'\n",
    "sample_annotation_path = 'BCCD_Dataset/BCCD/Annotations/BloodImage_00000.xml'\n",
    "\n",
    "# Загрузка изображения\n",
    "img = Image.open(sample_image_path)\n",
    "boxes, labels, orig_size = parse_voc_annotation(sample_annotation_path)\n",
    "\n",
    "print(f'Размер изображения: {orig_size}')\n",
    "print(f'Количество объектов: {len(boxes)}')\n",
    "print(f'Классы: {labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация примера с аннотациями\n",
    "def visualize_sample(image_path, annotation_path):\n",
    "    img = Image.open(image_path)\n",
    "    boxes, labels, (width, height) = parse_voc_annotation(annotation_path)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, figsize=(12, 9))\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    colors = {'WBC': 'red', 'RBC': 'blue', 'Platelets': 'green'}\n",
    "    \n",
    "    for box, label in zip(boxes, labels):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        xmin *= width\n",
    "        ymin *= height\n",
    "        xmax *= width\n",
    "        ymax *= height\n",
    "        \n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "        \n",
    "        rect = patches.Rectangle(\n",
    "            (xmin, ymin), w, h,\n",
    "            linewidth=2, edgecolor=colors[label], facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(xmin, ymin-5, label, color=colors[label], fontsize=12)\n",
    "    \n",
    "    ax.axis('off')\n",
    "    plt.title('Пример аннотированного изображения BCCD')\n",
    "    plt.show()\n",
    "\n",
    "visualize_sample(sample_image_path, sample_annotation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Статистика по датасету\n",
    "images_dir = config.TRAIN_IMAGES_DIR\n",
    "annotations_dir = config.TRAIN_ANNOTATIONS_DIR\n",
    "\n",
    "class_counts = {'WBC': 0, 'RBC': 0, 'Platelets': 0}\n",
    "total_images = 0\n",
    "\n",
    "for ann_file in os.listdir(annotations_dir):\n",
    "    if ann_file.endswith('.xml'):\n",
    "        ann_path = os.path.join(annotations_dir, ann_file)\n",
    "        _, labels, _ = parse_voc_annotation(ann_path)\n",
    "        for label in labels:\n",
    "            class_counts[label] += 1\n",
    "        total_images += 1\n",
    "\n",
    "print(f'\\nСтатистика датасета BCCD:')\n",
    "print(f'Всего изображений: {total_images}')\n",
    "print(f'\\nКоличество объектов по классам:')\n",
    "for cls, count in class_counts.items():\n",
    "    print(f'  {cls}: {count}')\n",
    "print(f'\\nВсего объектов: {sum(class_counts.values())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Создание модели SSD300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание модели\n",
    "device = config.DEVICE\n",
    "model = SSD300(n_classes=config.NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "\n",
    "# Подсчет параметров\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'Модель SSD300 создана')\n",
    "print(f'Всего параметров: {total_params:,}')\n",
    "print(f'Обучаемых параметров: {trainable_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание prior boxes\n",
    "priors = create_prior_boxes()\n",
    "print(f'Создано prior boxes: {priors.size(0)}')\n",
    "print(f'Размер prior boxes: {priors.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка forward pass\n",
    "dummy_input = torch.randn(1, 3, 300, 300).to(device)\n",
    "with torch.no_grad():\n",
    "    locs, scores = model(dummy_input)\n",
    "    \n",
    "print(f'Output shapes:')\n",
    "print(f'  Localization predictions: {locs.shape}')\n",
    "print(f'  Class scores: {scores.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание DataLoaders\n",
    "print('Создание DataLoaders...')\n",
    "train_loader, val_loader = create_dataloaders(train_split=0.8)\n",
    "\n",
    "print(f'Train batches: {len(train_loader)}')\n",
    "print(f'Val batches: {len(val_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настройка обучения\n",
    "priors = priors.to(device)\n",
    "criterion = MultiBoxLoss(priors, alpha=config.ALPHA)\n",
    "\n",
    "# Optimizer с разными learning rates для bias и weights\n",
    "biases = []\n",
    "not_biases = []\n",
    "for param_name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        if param_name.endswith('.bias'):\n",
    "            biases.append(param)\n",
    "        else:\n",
    "            not_biases.append(param)\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "    [\n",
    "        {'params': biases, 'lr': 2 * config.LEARNING_RATE},\n",
    "        {'params': not_biases}\n",
    "    ],\n",
    "    lr=config.LEARNING_RATE,\n",
    "    momentum=config.MOMENTUM,\n",
    "    weight_decay=config.WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer,\n",
    "    milestones=config.LR_DECAY_EPOCHS,\n",
    "    gamma=config.LR_DECAY_FACTOR\n",
    ")\n",
    "\n",
    "print('Optimizer и scheduler созданы')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции для обучения\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch+1}')\n",
    "    \n",
    "    for batch_idx, (images, boxes, labels) in enumerate(pbar):\n",
    "        images = images.to(device)\n",
    "        boxes = [b.to(device) for b in boxes]\n",
    "        labels = [l.to(device) for l in labels]\n",
    "        \n",
    "        # Forward pass\n",
    "        predicted_locs, predicted_scores = model(images)\n",
    "        \n",
    "        # Loss\n",
    "        loss = criterion(predicted_locs, predicted_scores, boxes, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', \n",
    "                         'avg_loss': f'{running_loss/(batch_idx+1):.4f}'})\n",
    "    \n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, boxes, labels in tqdm(dataloader, desc='Validation'):\n",
    "            images = images.to(device)\n",
    "            boxes = [b.to(device) for b in boxes]\n",
    "            labels = [l.to(device) for l in labels]\n",
    "            \n",
    "            predicted_locs, predicted_scores = model(images)\n",
    "            loss = criterion(predicted_locs, predicted_scores, boxes, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    return running_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение (можно уменьшить NUM_EPOCHS для быстрого теста)\n",
    "NUM_EPOCHS = 50  # Для демо используем 50 эпох\n",
    "\n",
    "os.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print('Начало обучения...')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Train\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss = validate(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # LR scheduler step\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'\\nEpoch {epoch+1}/{NUM_EPOCHS}:')\n",
    "    print(f'  Train Loss: {train_loss:.4f}')\n",
    "    print(f'  Val Loss: {val_loss:.4f}')\n",
    "    print(f'  LR: {optimizer.param_groups[0][\"lr\"]:.6f}\\n')\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_path = os.path.join(config.CHECKPOINT_DIR, 'best_model.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "        }, best_model_path)\n",
    "        print(f'Лучшая модель сохранена: {best_model_path}')\n",
    "\n",
    "print('Обучение завершено!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Оценка результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# График loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss (Log Scale)')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Лучший Val Loss: {best_val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inference на тестовых изображениях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка лучшей модели\n",
    "checkpoint = torch.load(os.path.join(config.CHECKPOINT_DIR, 'best_model.pth'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "print('Лучшая модель загружена для inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference на нескольких тестовых изображениях\n",
    "test_images = [\n",
    "    'BCCD_Dataset/BCCD/JPEGImages/BloodImage_00001.jpg',\n",
    "    'BCCD_Dataset/BCCD/JPEGImages/BloodImage_00010.jpg',\n",
    "    'BCCD_Dataset/BCCD/JPEGImages/BloodImage_00050.jpg',\n",
    "]\n",
    "\n",
    "for img_path in test_images:\n",
    "    if os.path.exists(img_path):\n",
    "        print(f'\\nОбработка: {img_path}')\n",
    "        boxes, labels, scores, original_image = detect(\n",
    "            img_path, model, device,\n",
    "            min_score=0.3,\n",
    "            max_overlap=0.45\n",
    "        )\n",
    "        \n",
    "        print(f'Найдено объектов: {boxes.size(0)}')\n",
    "        for i in range(boxes.size(0)):\n",
    "            label = labels[i].item()\n",
    "            if label > 0:\n",
    "                class_name = config.IDX_TO_CLASS[label]\n",
    "                score = scores[i].item()\n",
    "                print(f'  {class_name}: {score:.3f}')\n",
    "        \n",
    "        visualize_detection(original_image, boxes, labels, scores, show=True)\n",
    "    else:\n",
    "        print(f'Файл не найден: {img_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение финальной модели\n",
    "final_model_path = 'ssd300_bccd_final.pth'\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "print(f'Финальная модель сохранена: {final_model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заключение\n",
    "\n",
    "В этом notebook мы:\n",
    "1. Загрузили и исследовали датасет BCCD\n",
    "2. Реализовали архитектуру SSD300\n",
    "3. Обучили модель для детекции клеток крови\n",
    "4. Протестировали модель на новых изображениях\n",
    "\n",
    "### Дальнейшие улучшения:\n",
    "- Увеличить количество эпох обучения\n",
    "- Добавить более агрессивную аугментацию данных\n",
    "- Использовать другие backbone (ResNet, MobileNet)\n",
    "- Реализовать вычисление mAP метрики\n",
    "- Экспериментировать с гиперпараметрами"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
